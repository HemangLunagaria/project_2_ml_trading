{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation for training Machine Learning Models \r\n",
    "\r\n",
    "* In this notebook we will be using the price + indicator data which has been prepared in the previous notebook. We will set the features columns and the target data column. Then we will set aside a part of the data for testing.\r\n",
    "\r\n",
    "* We will use the GridSearchCV method of the scikit-learn library and check which model is giving the best score for training and validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### First read the data which has been prepared in the previous notebook "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_data = pd.read_csv('Resources/Data_plus_indicators.csv', index_col='Date', infer_datetime_format=True)\n",
    "df_data.rename(columns={'Daily_returns': 'Returns'}, inplace= True)\n",
    "df_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Our target value needs to be the returns of the next timeperiod, so transforming the data accordingly"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_data['Target_returns'] = df_data.Returns.shift(-1)\n",
    "df_data.dropna(inplace=True)\n",
    "df_data['Buy_or_sell'] = df_data.Target_returns.apply(lambda x: 1 if x > 0 else -1)\n",
    "df_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_data.Currency.unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing the data for training the classifier models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "curr_list = ['XLM/AUD', 'LTC/AUD', 'XRP/AUD', 'ETH/AUD', 'BCH/USD'] #, 'LTC/AUD'\n",
    "df_filtered = df_data.loc[ df_data.Currency.isin(curr_list) ]\n",
    "df_filtered.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df_filtered.loc[:,['SMA_agg', 'RSI_ratio', 'ADX_dirn', 'ATR_ratio', 'BBands_high', 'BBands_low']].reset_index(drop=True)        # , 'CCI', 'Returns'\n",
    "y = df_filtered.Buy_or_sell"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y.value_counts()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "resampler = SMOTE(random_state= 1)\n",
    "X , y = resampler.fit_resample(X , y)\n",
    "X.shape\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "logreg = LogisticRegression( solver='liblinear')\n",
    "forest = RandomForestClassifier( criterion='gini')\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "ada_boost = AdaBoostClassifier()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross-validate a Pipeline with 1 feature"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "col_transform = make_column_transformer(\n",
    "    (StandardScaler(), X.columns.to_list())\n",
    ")\n",
    "col_transform.fit_transform(X);\n",
    "\n",
    "pca = PCA(n_components=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# chain sequential steps together\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "# pipe = make_pipeline(col_transform, dec_tree)\n",
    "pipe = Pipeline(steps= [('col_transform', col_transform), \n",
    "                        ('pca', pca),\n",
    "                        # ('dec_tree', dec_tree)\n",
    "                        # ('forest', forest)\n",
    "                        # ('grad_boost', grad_boost)\n",
    "                        ('ada_boost', ada_boost)\n",
    "                    ])\n",
    "\n",
    "# (col_transform, dec_tree)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cross-validate the entire process\n",
    "# thus, preprocessing occurs within each fold of cross-validation\n",
    "cross_val_score(pipe, X, y, cv=10, scoring='accuracy').mean()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Attempt 1: GridSearch using 1 classifier at a time"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {}\n",
    "# params['logisticregression__C'] = [0.05, 0.06, 0.07]\n",
    "# params['logisticregression__penalty'] = ['l1']\n",
    "\n",
    "# params['dec_tree__criterion'] = ['gini']\n",
    "\n",
    "# params['forest__n_estimators'] = list(range(100,150,10))\n",
    "# params['forest__max_depth'] = list(range(3,6,1))\n",
    "# params['forest__max_features'] = list(range(2,4,1))\n",
    "\n",
    "# params['grad_boost__learning_rate'] = [0.1, 0.3, 0.5]\n",
    "# params['grad_boost__n_estimators'] = list(range(100,200,10))\n",
    "# params['grad_boost__max_features'] = ['auto', 'sqrt', 'log2']\n",
    "# params['grad_boost__max_depth'] = list(range(3,8,1))\n",
    "# params['grad_boost__loss'] = ['deviance', 'exponential']\n",
    "\n",
    "params['ada_boost__n_estimators'] = list(range(120,160,10))\n",
    "params['ada_boost__learning_rate'] = [ 0.25, 0.5, 0.75]\n",
    "# params['ada_boost__algorithm'] = ['SAMME', 'SAMME.R']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid = GridSearchCV(pipe, params, cv=10, scoring='accuracy')\n",
    "grid.fit(X,y);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f'Score: {grid.best_score_}')\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "estimator = grid.best_estimator_['ada_boost']\n",
    "estimator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "estimator.feature_importances_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Testing\n",
    "df_testing = df_data.loc[ df_data.Currency == 'ADA/AUD' ]\n",
    "X_test = df_testing.loc[: , ['SMA_agg', 'RSI_ratio', 'ADX_dirn', 'ATR_ratio', 'BBands_high', 'BBands_low']].reset_index(drop=True)   # , 'CCI', 'Returns'\n",
    "y_test = df_testing.Buy_or_sell\n",
    "\n",
    "print(f'{X_test.shape}; {y_test.shape}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pipeline = make_pipeline(col_transform, pca, estimator)\n",
    "pipeline.fit(X, y)\n",
    "df_pred = pd.DataFrame(pipeline.predict(X_test))\n",
    "df_pred.value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pipeline.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report\n",
    "df_predictions = pd.DataFrame(pipeline.predict(X_test), columns=['Buy'])\n",
    "report = classification_report(y_test, pipeline.predict(X_test), output_dict=True)\n",
    "report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Attempt 2 - Multiple Classifiers in a single GridSearch Call"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from CronJobs import predictions as pr\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "print(pr.printcwd())\n",
    "\n",
    "# print(df)\n",
    "# df.head(5)\n",
    "# print(len(result))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/hemanglunagaria/Documents/Monash_FinTech_repos/project_2_ml_trading/Data_ML_models_training\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from CronJobs import predictions as pr\n",
    "\n",
    "pr.getOHLCData_sync()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from CronJobs import predictions as pr\n",
    "\n",
    "pr.predictions()\n",
    "\n",
    "*/2 * * * * /Users/hemanglunagaria/Documents/Monash_FinTech_repos/project_2_ml_trading/cron_job_script > /tmp/stdout.log 2> /tmp/stderr.log"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('mlenv': conda)"
  },
  "interpreter": {
   "hash": "3cf02f8c69f7cc96a4f38b5eec7930a98857bcc2cd2c2e6eecd2d1f6e42fcb50"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}