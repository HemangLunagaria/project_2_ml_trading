{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Machine Learning Process\n",
    "---\n",
    "\n",
    "![Process Diagram](Data_ML_models_training/Images/ML_process.png)\n",
    "\n"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Index\r\n",
    "---\r\n",
    "\r\n",
    "## Data Fetch\r\n",
    "\r\n",
    "> Jupyter Notebook - [yfinance_data_for_training.ipynb](Data_ML_models_training/yfinance_data_for_training.ipynb)\r\n",
    ">\r\n",
    "> Jupyter Notebook - [CCXT_data_for_testing.ipynb](Data_ML_models_training/CCXT_data_for_testing.ipynb)\r\n",
    "---\r\n",
    "\r\n",
    "## Clean, Prepare & Manipulate Data\r\n",
    "\r\n",
    "> Functions for calculating and adding Technical Indicators - [CronJobs/Utility_Functions/Functions.py](Data_ML_models_training/CronJobs/Utility_Functions/Functions.py)\r\n",
    ">\r\n",
    "> Computing Target Values, Feature Selection and Pre-processing - [Feature_sel_and_ML_training.ipynb](Data_ML_models_training/Feature_sel_and_ML_training.ipynb)"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1 - Get Data"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Data from yfinance. \n",
    "\n",
    "[Jupyter Notebook](Data_ML_models_training/yfinance_data_for_training.ipynb)"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Import libraries and dependencies\r\n",
    "import ccxt\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from dotenv import load_dotenv\r\n",
    "import talib as ta\r\n",
    "import yfinance as yf \r\n",
    "import datetime as dt \r\n",
    "\r\n",
    "from CronJobs.Utility_Functions import Functions"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "currs_list = [ 'BTC-AUD', 'ETH-AUD', 'XRP-AUD' , 'LTC-AUD', 'ADA-AUD', 'XLM-AUD', 'BCH-AUD']\r\n",
    "start_date = '2019-06-01'\r\n",
    "end_date = '2021-09-01'\r\n",
    "interval = '1h'\r\n",
    "\r\n",
    "df_data = yf.download(currs_list, start= start_date, end= end_date, interval= interval, group_by= 'ticker')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[*********************100%***********************]  7 of 7 completed\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing Data using CCXT with Kraken as Exchange\r\n",
    "\r\n",
    "[Jupyter Notbook](Data_ML_models_training/CCXT_data_for_testing.ipynb)"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "currs_list = ['ETH/AUD', 'XRP/AUD' , 'LTC/AUD', 'ADA/AUD', 'XLM/AUD', 'BCH/AUD']     #\r\n",
    "\r\n",
    "dict_ohlcv = {}\r\n",
    "\r\n",
    "for curr in currs_list:\r\n",
    "    \r\n",
    "    # Call data fetch\r\n",
    "    ohlcv = exchange.fetchOHLCV(curr, '1h')\r\n",
    "\r\n",
    "    # Store the values in a dataframe\r\n",
    "    df_ohlcv = pd.DataFrame(ohlcv, columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume']).set_index('Date')\r\n",
    "    df_ohlcv.index = pd.to_datetime(df_ohlcv.index, unit='ms')\r\n",
    "\r\n",
    "    df_ohlcv.dropna(inplace=True)\r\n",
    "\r\n",
    "    # Store the symbol name and history data in a dict \r\n",
    "    dict_ohlcv[curr] = df_ohlcv \r\n",
    "\r\n",
    "    start_date = df_ohlcv.index[0].date().isoformat()\r\n",
    "    end_date = df_ohlcv.index[-1].date().isoformat()\r\n",
    "    num_records = (len(df_ohlcv))\r\n",
    "    start_price = df_ohlcv.iloc[0]['Close']\r\n",
    "    end_price = df_ohlcv.iloc[-1]['Close']\r\n",
    "\r\n",
    "    print(f'Data summary for {curr}')\r\n",
    "    print(f'    Start Date: {start_date}; End Date: {end_date}; NUmber of records: {num_records}')\r\n",
    "    print(f'    Start Price: {start_price}; End Price: {end_price}')    \r\n",
    "    print(f'Data for {curr} fetched and appended into the dictionary\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data summary for ETH/AUD\n",
      "    Start Date: 2021-08-06; End Date: 2021-09-05; NUmber of records: 720\n",
      "    Start Price: 3796.86; End Price: 5267.66\n",
      "Data for ETH/AUD fetched and appended into the dictionary\n",
      "\n",
      "Data summary for XRP/AUD\n",
      "    Start Date: 2021-08-06; End Date: 2021-09-05; NUmber of records: 720\n",
      "    Start Price: 0.99639; End Price: 1.69548\n",
      "Data for XRP/AUD fetched and appended into the dictionary\n",
      "\n",
      "Data summary for LTC/AUD\n",
      "    Start Date: 2021-08-06; End Date: 2021-09-05; NUmber of records: 720\n",
      "    Start Price: 189.52; End Price: 292.43\n",
      "Data for LTC/AUD fetched and appended into the dictionary\n",
      "\n",
      "Data summary for ADA/AUD\n",
      "    Start Date: 2021-08-06; End Date: 2021-09-05; NUmber of records: 720\n",
      "    Start Price: 1.87313; End Price: 3.87422\n",
      "Data for ADA/AUD fetched and appended into the dictionary\n",
      "\n",
      "Data summary for XLM/AUD\n",
      "    Start Date: 2021-08-06; End Date: 2021-09-05; NUmber of records: 720\n",
      "    Start Price: 0.37792; End Price: 0.50057\n",
      "Data for XLM/AUD fetched and appended into the dictionary\n",
      "\n",
      "Data summary for BCH/AUD\n",
      "    Start Date: 2021-08-06; End Date: 2021-09-05; NUmber of records: 720\n",
      "    Start Price: 724.68; End Price: 955.53\n",
      "Data for BCH/AUD fetched and appended into the dictionary\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2 - Clean, Prepare, Manipulate Data and Feature Selection"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Function for calculating and adding Technical Indicators\r\n",
    "\r\n",
    "Function .py file - [CronJobs/Utility_Functions/Functions.py](Data_ML_models_training/CronJobs/Utility_Functions/Functions.py)\r\n",
    "\r\n",
    "Library - TA-lib\r\n",
    "\r\n",
    "Indicators Used:\r\n",
    "\r\n",
    "- Momentum Indicators - SMA, RSI, CCI, MACD\r\n",
    "- Trend Strength Indicators - ADX\r\n",
    "- Volatility Indicators - ATR, Bollinger Bands\r\n",
    "- Volume Indicators - SMA(Volume)"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def add_tech_indicators(df, fast, slow):\r\n",
    "    \r\n",
    "#---------------------------------------------------------------------\r\n",
    "# Momentum Indicators\r\n",
    "#---------------------------------------------------------------------\r\n",
    "# SMA indicators fast and slow\r\n",
    "    sma_fast = ta.SMA(df['Close'], timeperiod=fast )\r\n",
    "    sma_slow = ta.SMA(df['Close'], timeperiod=slow )\r\n",
    "    df['SMA_agg'] = sma_fast / sma_slow \r\n",
    "\r\n",
    "# RSI Ratio\r\n",
    "    rsi_fast = ta.RSI(df['Close'], fast)\r\n",
    "    rsi_slow = ta.RSI(df['Close'], slow)\r\n",
    "    df['RSI_ratio'] = rsi_fast / rsi_slow\r\n",
    "\r\n",
    "# CCI\r\n",
    "    df['CCI'] = ta.CCI(df['High'], df['Low'], df['Close'], fast)\r\n",
    "\r\n",
    "# MACD\r\n",
    "# We'll be using MACD_ratio which is MACD / Signal. We will multiply it by -1 if MACD is lesser than 0. \r\n",
    "# So the MACD ratio will range from:\r\n",
    "    # ratio < -1, when the MACD is below 0 and MACD is below Signal line \r\n",
    "    # -1 > ratio > 0, when the MACD is above Signal line but below 0\r\n",
    "    # 0 < ratio < 1, when MACD is below signal but above 0 \r\n",
    "    # 1 < ratio, when MACD is above 0 and above the signal line \r\n",
    "    df['MACD'], df['Signal'], hist = ta.MACD(df['Close'], fastperiod=fast, slowperiod=slow, signalperiod=8) \r\n",
    "    df['MACD_ratio'] =  df['MACD'] / df['Signal']\r\n",
    "    df['MACD_ratio'] = df['MACD_ratio'] * df['MACD'] / abs(df['MACD'])          \r\n",
    "\r\n",
    "    df.drop(columns= ['MACD', 'Signal'], inplace = True)\r\n",
    "\r\n",
    "#---------------------------------------------------------------------\r\n",
    "# Trend Strength Indicators\r\n",
    "#---------------------------------------------------------------------\r\n",
    "# ADX\r\n",
    "    df['ADX'] = ta.ADX(df['High'], df['Low'], df['Close'], timeperiod= fast)\r\n",
    "    df['plus_DI'] = ta.PLUS_DI(df['High'], df['Low'], df['Close'], timeperiod= fast)\r\n",
    "    df['minus_DI'] = ta.MINUS_DI(df['High'], df['Low'], df['Close'], timeperiod= fast)\r\n",
    "    df['ADX_dirn'] = np.where(df['plus_DI'] > df['minus_DI'], 1.0, 0.0)\r\n",
    "\r\n",
    "    df.drop(columns=['plus_DI', 'minus_DI'], inplace=True)\r\n",
    "\r\n",
    "#---------------------------------------------------------------------\r\n",
    "# Volatility Indicators\r\n",
    "#---------------------------------------------------------------------\r\n",
    "# ATR Ratio: fast / slow. if value is less than 1, the price volatility is slowing\r\n",
    "    atr_fast = ta.ATR(df['High'], df['Low'], df['Close'], timeperiod= fast)\r\n",
    "    atr_slow = ta.ATR(df['High'], df['Low'], df['Close'], timeperiod= slow)\r\n",
    "    df['ATR_ratio'] = atr_fast / atr_slow\r\n",
    "\r\n",
    "# Bollinger Bands: periods = fast; Std.Dev = 1\r\n",
    "    df['BBands_high'], middle, df['BBands_low']  = ta.BBANDS(df['Close'], timeperiod= fast, nbdevup= 1, nbdevdn= 1)\r\n",
    "\r\n",
    "    df['BBands_high'] = df['BBands_high'] / df['Close']             # Value lesser than 1 will mean price has crossed above upper band\r\n",
    "    df['BBands_low'] = df['Close'] / df['BBands_low']               # Value lesser than 1 will mean price has crossed below lower band\r\n",
    "\r\n",
    "#---------------------------------------------------------------------\r\n",
    "# Volume Indicators\r\n",
    "#---------------------------------------------------------------------\r\n",
    "# # SMA indicators fast and slow\r\n",
    "    sma_vol_fast = ta.SMA(df['Volume'], timeperiod=fast )\r\n",
    "    sma_vol_slow = ta.SMA(df['Volume'], timeperiod=slow )\r\n",
    "    df['SMA_vol_agg'] = sma_vol_fast / sma_vol_slow \r\n",
    "\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data manipulation - Computing Target Values"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_data['Target_returns'] = df_data.Returns.shift(-1)\r\n",
    "df_data.dropna(inplace=True)\r\n",
    "df_data['Buy_or_sell'] = df_data.Target_returns.apply(lambda x: 1 if x > 0 else 0)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Selection \r\n",
    "\r\n",
    "[Jupyter Notbook](Data_ML_models_training/Feature_sel_and_ML_training.ipynb)\r\n",
    "\r\n",
    "Library used sklearn.feature_selection\r\n",
    "\r\n",
    "Techniques used - SelectKBest(f_classific), VarianceThreshold(threshold of 0.8)\r\n",
    "\r\n",
    "Process - Ran the SelectKBest method and discarded 3 features which were least relevant\r\n",
    "\r\n",
    "## Resampling \r\n",
    "\r\n",
    "[Jupyter Notbook](Data_ML_models_training/Feature_sel_and_ML_training.ipynb)\r\n",
    "\r\n",
    "Library used imblearn.combine\r\n",
    "\r\n",
    "Technique used - SMOTEENN"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3 - ML Model Selection, Hypertuning and Training"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Jupyter Notbook](Data_ML_models_training/Feature_sel_and_ML_training.ipynb)\r\n",
    "\r\n",
    "Libraries used - sklearn.model_selection, sklearn.preprocessing, sklearn.compose, sklearn.decomposition, sklearn.pipeline\r\n",
    "\r\n",
    "Models used for evaluation\r\n",
    "\r\n",
    "- SVC\r\n",
    "- Logistic Regression\r\n",
    "- Decision Tree Classifier\r\n",
    "- Random Forest Classifier\r\n",
    "- Gradient Boosting Classifier\r\n",
    "- Ada Boost\r\n",
    "\r\n",
    "Steps in Pipeline\r\n",
    "\r\n",
    "- StandardScaler\r\n",
    "- Model\r\n",
    "\r\n",
    "Steps in Model Selection\r\n",
    "\r\n",
    "- sklearn.model_selection -> cross_val_score using 'roc_auc' and 'accuracy'\r\n",
    "- sklearn.model_selection -> GridSearchCV using 'roc_auc'"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing steps\n",
    "\n",
    "1. Column Transformation using `make_column_transformer` method of sklearn.compose\n",
    "\n",
    "2. Column Transformer to run StandardScaler on the 8 best indicators determined in Feature Selection\n",
    "\n",
    "3. Defined pipeline with column transformation as first step"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Column Transformer with the 8 best indicators selected from Feature Selection step\r\n",
    "col_transform = make_column_transformer(\r\n",
    "    (StandardScaler(), best_inds ),\r\n",
    "    remainder='drop'\r\n",
    ")\r\n",
    "col_transform.fit_transform(X);"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Defining pipeline with the columntransformer and model selected for training\r\n",
    "if model_for_testing == 'svc': model = ('svc', SVC() )\r\n",
    "elif model_for_testing == 'logreg': model = ('logreg', LogisticRegression( ))\r\n",
    "elif model_for_testing == 'dec_tree': model = ('dec_tree', DecisionTreeClassifier())\r\n",
    "elif model_for_testing == 'forest': model = ('forest', RandomForestClassifier( ))\r\n",
    "elif model_for_testing == 'grad_boost': model = ('grad_boost', GradientBoostingClassifier())\r\n",
    "elif model_for_testing == 'ada_boost': model = ('ada_boost', AdaBoostClassifier())\r\n",
    "\r\n",
    "pipe = Pipeline(steps= [('col_transform', col_transform), \r\n",
    "                    # ('pca', pca),\r\n",
    "                    model\r\n",
    "                    ])"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection\n",
    "\n",
    "Steps involved:\n",
    "\n",
    "1. Ran `cross_val_score` with on the models with default parameters and 10-fold Cross Validation to get the benchmark scores\n",
    "\n",
    "2. Ran GridSearchCV on a range of parameters to get the optimal model configuration"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cross-validate the entire process\r\n",
    "# thus, preprocessing occurs within each fold of cross-validation\r\n",
    "cross_val_roc_auc = cross_val_score(pipe, X, y, cv=10, scoring='roc_auc', n_jobs=20).mean()\r\n",
    "\r\n",
    "cross_val_accuracy = cross_val_score(pipe, X, y, cv=10, scoring='accuracy', n_jobs=20).mean()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid = GridSearchCV(pipe, params, cv=10, scoring='roc_auc', n_jobs=20)\r\n",
    "grid.fit(X,y);\r\n",
    "\r\n",
    "print(f'Score: {grid.best_score_}')\r\n",
    "print(f'Best params: {grid.best_params_}')\r\n",
    "estimator = grid.best_estimator_[model_for_testing]\r\n",
    "\r\n",
    "grid_best_params = str(grid.best_params_)\r\n",
    "grid_best_params\r\n",
    "gridcv_best_score = grid.best_score_"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fitting the pipeline with the tuned model and saving it to a joblib"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fitting the pipeline, with the tuned model\r\n",
    "pipeline = make_pipeline(col_transform, \r\n",
    "            # pca, \r\n",
    "            estimator)\r\n",
    "pipeline.fit(X, y)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from joblib import dump, load\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "filename = Path('Joblibs/' + dt.date.today().isoformat() + '_' + model_for_testing + '_Feat_sel.joblib')\r\n",
    "dump(pipeline, filename)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4 - Testing"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Jupyter Notbook](Data_ML_models_training/Backtest_Mach_learn.ipynb)\r\n",
    "\r\n",
    "## Set Control parameters for the backtest and run the predictions"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_for_testing = '2021-09-01_ada_boost_Feat_sel.joblib'\r\n",
    "\r\n",
    "curr_list = ['BTC/AUD', 'ETH/AUD', 'XRP/AUD', 'LTC/AUD', 'ADA/AUD', 'XLM/AUD', 'BCH/AUD']\r\n",
    "\r\n",
    "all_inds = ['SMA_agg', 'RSI_ratio', 'CCI', 'MACD_ratio', 'ADX', 'ADX_dirn', 'ATR_ratio', 'BBands_high', 'BBands_low', 'SMA_vol_agg', 'Returns']\r\n",
    "\r\n",
    "df_cml_rets = pd.DataFrame()\r\n",
    "df_hourly_rets = pd.DataFrame()\r\n",
    "\r\n",
    "for curr_tested in curr_list:\r\n",
    "\r\n",
    "    df_testing_subset = df_all_data.loc[ df_all_data.Currency == curr_tested].copy()\r\n",
    "    df_testing_subset.sort_index(inplace=True)\r\n",
    "\r\n",
    "    X_test = df_testing_subset.loc[: , all_inds].reset_index(drop=True)   \r\n",
    "    y_test = df_testing_subset.loc[:, ['Target_returns', 'Buy_or_sell']].copy()\r\n",
    "\r\n",
    "    # Run the predictions\r\n",
    "    df_pred = y_test\r\n",
    "    df_pred['Pred_buy_or_sell'] = pipeline.predict(X_test)\r\n",
    "\r\n",
    "    print(f'\\nClassification report for {curr_tested}')\r\n",
    "    print(classification_report(y_test.Buy_or_sell, df_pred.Pred_buy_or_sell))\r\n",
    "\r\n",
    "    hourly_returns = df_pred['Target_returns'] * df_pred['Pred_buy_or_sell']\r\n",
    "    cum_rets = (1 + hourly_returns).cumprod()\r\n",
    "    total_returns = round((cum_rets[-1] - cum_rets[0]) * 100, 2)\r\n",
    "\r\n",
    "    col_name = 'hourly_rets_'  + (curr_tested.replace('/', '-'))\r\n",
    "    df_hourly_rets[col_name] = hourly_returns\r\n",
    "\r\n",
    "    col_name = 'cum_rets_' + (curr_tested.replace('/', '-'))\r\n",
    "    df_cml_rets[col_name] = cum_rets"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate Performance Metrics"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metrics = [ 'Annual Return', 'Cumulative Returns', 'Annual Volatility', 'Sharpe Ratio', 'Sortino Ratio']\r\n",
    "\r\n",
    "columns = ['Backtest']\r\n",
    "\r\n",
    "# Initialize the DataFrame with index set to evaluation metrics and column as `Backtest` (just like PyFolio)\r\n",
    "portfolio_evaluation_df = pd.DataFrame(index=metrics, columns=columns)\r\n",
    "\r\n",
    "# Calculate cumulative return\r\n",
    "portfolio_evaluation_df.loc['Cumulative Returns'] = df_portfolio_returns['cum_rets_agg'][-1]\r\n",
    "\r\n",
    "# Calculate annualized return\r\n",
    "portfolio_evaluation_df.loc['Annual Return'] = ( df_portfolio_returns['hourly_rets_agg'].mean() * 24 * 365 )\r\n",
    "\r\n",
    "# Calculate annual volatility\r\n",
    "portfolio_evaluation_df.loc['Annual Volatility'] = ( df_portfolio_returns['hourly_rets_agg'].std() * np.sqrt(24 * 365) )\r\n",
    "\r\n",
    "# Calculate Sharpe Ratio\r\n",
    "portfolio_evaluation_df.loc['Sharpe Ratio'] = ( df_portfolio_returns['hourly_rets_agg'].mean() * 24 * 365) / \r\n",
    "    ( df_portfolio_returns['hourly_rets_agg'].std() * np.sqrt(24 * 365) )\r\n",
    "\r\n",
    "# Calculate Downside Return\r\n",
    "sortino_ratio_df = df_portfolio_returns[['hourly_rets_agg']].copy()\r\n",
    "sortino_ratio_df.loc[:,'Downside Returns'] = 0\r\n",
    "\r\n",
    "target = 0\r\n",
    "mask = sortino_ratio_df['hourly_rets_agg'] < target\r\n",
    "sortino_ratio_df.loc[mask, 'Downside Returns'] = sortino_ratio_df['hourly_rets_agg']**2\r\n",
    "\r\n",
    "# Calculate Sortino Ratio\r\n",
    "down_stdev = np.sqrt(sortino_ratio_df['Downside Returns'].mean()) * np.sqrt(24 * 365)\r\n",
    "expected_return = sortino_ratio_df['hourly_rets_agg'].mean() * 24 * 365\r\n",
    "sortino_ratio = expected_return/down_stdev\r\n",
    "\r\n",
    "portfolio_evaluation_df.loc['Sortino Ratio'] = sortino_ratio"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Backtest Results\r\n",
    "\r\n",
    "Strategy Performance on individual currency pairs\r\n",
    "\r\n",
    "|![BTC-AUD](Data_ML_models_training/Backtest_results/Results_BTC-AUD.png) | ![ETH-AUD](Data_ML_models_training/Backtest_results/Results_ETH-AUD.png) | ![BCH-AUD](Data_ML_models_training/Backtest_results/Results_BCH-AUD.png)\r\n",
    "|---|---|---\r\n",
    "|![ADA-AUD](Data_ML_models_training/Backtest_results/Results_ADA-AUD.png) | ![XRP-AUD](Data_ML_models_training/Backtest_results/Results_XRP-AUD.png) | ![XLM-AUD](Data_ML_models_training/Backtest_results/Results_XLM-AUD.png)\r\n",
    "|![LTC-AUD](Data_ML_models_training/Backtest_results/Results_LTC-AUD.png)||"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Strategy Performance for the portfolio of the 7 currency pairs\r\n",
    "\r\n",
    "Cumulative Returns\r\n",
    "\r\n",
    "> ![Portfolio Returns](Data_ML_models_training/Backtest_results/Portfolio_Results-2021-08-04_to_2021-09-03.png)\r\n",
    "\r\n",
    "Metrics\r\n",
    "\r\n",
    "> ![Portfolio metrics](Data_ML_models_training/Backtest_results/Portfolio_metrics.png)"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "cc9d93f5fa92246aacb984fbac88763759a8f65daad4aaedd794ab683a30e53f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}