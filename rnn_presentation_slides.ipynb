{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM RNN Crypto Predictor Using Closing Price & Returns\n",
    "\n",
    "One of the Machine Learning models used in this project is the deep learning Recurrent Neural Networks or RNN to model the Cryptos closing prices and returns. Both models use a rolling window of Xt-n to predict Xt."
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Steps taken"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the data for training and testing\n",
    "\n",
    "For both the models the historical data was sourced from yahoo finance and exported to a csv file.\n",
    "\n",
    "We used the window_data function to generate the X and y values for the model, this function accepts the column number for the features (X) and the target (y). It chunks the data up with a rolling window of Xt-n to predict Xt and returns a numpy array of X and y.\n",
    "\n",
    "The features and test data sets were then split in a 70%-30% ratio for training and testing and to remove bias the split values were then scaled using a MinMaxScaler scaler.\n",
    "\n",
    "After trying out multiple combinations we used a rolling 24-hour window to predict the 25th hour or the next day opening price/returns, because that gave the least loss value.\n",
    "\n",
    "Finally, the X_train and X_test values were reshaped to fit the model's requirement of samples. \n",
    "\n"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build and train custom LSTM RNNs\n",
    "\n",
    "The LSTM RNNs were built for the Closing Prices model using the same configuration."
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM for Closing prices model\n",
    "\n",
    "![LSTM Closing prices model](Data_ML_models_training/Images/LSTM_closing_prices_model.png)"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build and train custom LSTM RNNs\n",
    "\n",
    "The LSTM RNNs were built for the Returns model using the same configuration."
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM for Returns model\n",
    "\n",
    "![LSTM returns model](Data_ML_models_training/Images/LSTM_returns_model.png)"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the data for training and testing\n",
    "\n",
    "For both the models the historical data was sourced from yahoo finance and exported to a csv file.\n",
    "\n",
    "We used the window_data function to generate the X and y values for the model, this function accepts the column number for the features (X) and the target (y). It chunks the data up with a rolling window of Xt-n to predict Xt and returns a numpy array of X and y.\n",
    "\n",
    "The features and test data sets were then split in a 70%-30% ratio for training and testing and to remove bias the split values were then scaled using a MinMaxScaler scaler.\n",
    "\n",
    "After trying out multiple combinations we used a rolling 24-hour window to predict the 25th hour or the next day opening price/returns, because that gave the least loss value.\n",
    "\n",
    "Finally, the X_train and X_test values were reshaped to fit the model's requirement of samples. \n",
    "\n"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the performance of each model\n",
    "\n",
    "\n",
    "The models were compiled and then trained with multiple combinations of parameters. Finally, the optimal results were obtained with the following parameters (for both models):\n",
    "\n",
    "•\tNumber of units: 24\n",
    "\n",
    "•\tEpochs: 20\n",
    "\n",
    "•\tBatch size: 1\n",
    "\n",
    "•\tOptimizer: adam\n",
    "\n",
    "•\tLoss: mean_squared_error (since the value we want to predict is continuous)\n",
    "\n",
    "•\tDropout layer: 0.2 (to prevent overfitting)\n",
    "\n",
    "•\tShuffle: false (to keep the sequential order of the data since we are working with time-series) \n",
    "\n",
    "The predicted prices were then compared with the actual test results and were plotted in a line chart.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Charts using the Closing prices LSTM model for the Cryptos were as below:\n",
    "\n",
    "![Chart - LSTM Closing Prices model](Data_ML_models_training/Images/LSTM_closing_prices_chart.png)"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Charts using the Returns LSTM model for the Cryptos were as below:\n",
    "\n",
    "![Chart - LSTM Returns model](Data_ML_models_training/Images/LSTM_returns_chart.png)"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Using the above analysis, the following questions were answered:\n",
    "\n",
    "Q. Which model has a lower loss?\n",
    "\n",
    "A. The LSTM model using Returns had a lower loss value on average.\n",
    "\n",
    "Q. Which model tracks the actual values better over time?\n",
    "\n",
    "A. The LSTM model which used the Returns tracked the actual values better over time\n",
    "\n",
    "Q. Which window size works best for the model?\n",
    "\n",
    "A. After trying different values, 24 hour rolling window was appropriate.\n",
    "\n",
    "## What would you reasearch next, if you had two more weeks?\n",
    "\n",
    "There is always space for improvement, the fuel of an RNN model is data so we can build a more robust and accurate model by collecting more data.\n",
    "\n",
    "We can also try to adjust the number of nodes in a layer or add additional LSTM layers, we could also experiment with the batch size parameter; however a smaller batch size is always recommended.\n",
    " \n",
    "\n"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}